wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.8.2
    cli_version: 0.15.12
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1704757438.680075
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 1
      - 22
      - 23
      - 35
      4: 3.8.2
      5: 0.15.12
      8:
      - 3
      - 5
      13: windows-amd64
algo:
  desc: null
  value: SAC
policy_class:
  desc: null
  value: <class 'stable_baselines3.sac.policies.MultiInputPolicy'>
device:
  desc: null
  value: cuda
verbose:
  desc: null
  value: 1
policy_kwargs:
  desc: null
  value: '{''net_arch'': [512, 512, 512], ''use_sde'': False}'
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 100000
_num_timesteps_at_start:
  desc: null
  value: 0
seed:
  desc: null
  value: None
action_noise:
  desc: null
  value: None
start_time:
  desc: null
  value: 1704757443109367300
learning_rate:
  desc: null
  value: 1.0e-06
tensorboard_log:
  desc: null
  value: runs
_last_obs:
  desc: null
  value: "OrderedDict([('achieved_goal', array([[ 1.4332033,  4.302799 , -4.476341\
    \ ,  1.4281572, -1.3092537,\n        -1.4845116,  0.       ,  0.       , -4.476341\
    \ ,  1.4281572]],\n      dtype=float32)), ('desired_goal', array([[0., 0., 0.,\
    \ 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)), ('observation', array([[ 1.4332033,\
    \  4.302799 , -4.476341 ,  1.4281572, -1.3092537,\n        -1.4845116,  0.   \
    \    ,  0.       , -4.476341 ,  1.4281572]],\n      dtype=float32))])"
_last_episode_starts:
  desc: null
  value: '[ True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000237E183D9D0>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: 'Dict(''achieved_goal'': Box(-1.0, 1.0, (10,), float32), ''desired_goal'':
    Box(-1.0, 1.0, (10,), float32), ''observation'': Box(-1.0, 1.0, (10,), float32))'
action_space:
  desc: null
  value: Box(-1.0, 1.0, (2,), float32)
n_envs:
  desc: null
  value: 1
buffer_size:
  desc: null
  value: 1000000
batch_size:
  desc: null
  value: 1024
learning_starts:
  desc: null
  value: 100
tau:
  desc: null
  value: 0.05
gamma:
  desc: null
  value: 0.95
gradient_steps:
  desc: null
  value: 1
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <her_replay.HerReplayBuffer object at 0x00000237E183D7F0>
replay_buffer_class:
  desc: null
  value: <class 'her_replay.HerReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{''n_sampled_goal'': 4, ''goal_selection_strategy'': ''future'', ''env'':
    <frcenv.FRCEnv object at 0x00000237D0350D00>}'
_episode_storage:
  desc: null
  value: None
train_freq:
  desc: null
  value: 'TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: ''step''>)'
use_sde_at_warmup:
  desc: null
  value: 'False'
target_entropy:
  desc: null
  value: -2.0
log_ent_coef:
  desc: null
  value: tensor([0.], device='cuda:0', requires_grad=True)
ent_coef:
  desc: null
  value: auto
target_update_interval:
  desc: null
  value: 1
ent_coef_optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 1e-06\n    maximize: False\n    weight_decay:\
    \ 0\n)"
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x00000237DD1AD550>
policy:
  desc: null
  value: "MultiInputPolicy(\n  (actor): Actor(\n    (features_extractor): CombinedExtractor(\n\
    \      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1,\
    \ end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n    \
    \    (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (latent_pi):\
    \ Sequential(\n      (0): Linear(in_features=30, out_features=512, bias=True)\n\
    \      (1): ReLU()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (3): ReLU()\n      (4): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (5): ReLU()\n    )\n    (mu): Linear(in_features=512, out_features=2, bias=True)\n\
    \    (log_std): Linear(in_features=512, out_features=2, bias=True)\n  )\n  (critic):\
    \ ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n      (extractors):\
    \ ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n   \
    \     (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation):\
    \ Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0): Sequential(\n \
    \     (0): Linear(in_features=32, out_features=512, bias=True)\n      (1): ReLU()\n\
    \      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): ReLU()\n\
    \      (4): Linear(in_features=512, out_features=512, bias=True)\n      (5): ReLU()\n\
    \      (6): Linear(in_features=512, out_features=1, bias=True)\n    )\n    (qf1):\
    \ Sequential(\n      (0): Linear(in_features=32, out_features=512, bias=True)\n\
    \      (1): ReLU()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (3): ReLU()\n      (4): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (5): ReLU()\n      (6): Linear(in_features=512, out_features=1, bias=True)\n\
    \    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n\
    \      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1,\
    \ end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n    \
    \    (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0):\
    \ Sequential(\n      (0): Linear(in_features=32, out_features=512, bias=True)\n\
    \      (1): ReLU()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (3): ReLU()\n      (4): Linear(in_features=512, out_features=512, bias=True)\n\
    \      (5): ReLU()\n      (6): Linear(in_features=512, out_features=1, bias=True)\n\
    \    )\n    (qf1): Sequential(\n      (0): Linear(in_features=32, out_features=512,\
    \ bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=512, out_features=512,\
    \ bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=512, out_features=512,\
    \ bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=512, out_features=1,\
    \ bias=True)\n    )\n  )\n)"
actor:
  desc: null
  value: "Actor(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n\
    \      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal):\
    \ Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1,\
    \ end_dim=-1)\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=30,\
    \ out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (5): ReLU()\n  )\n  (mu): Linear(in_features=512,\
    \ out_features=2, bias=True)\n  (log_std): Linear(in_features=512, out_features=2,\
    \ bias=True)\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors):\
    \ ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n     \
    \ (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1,\
    \ end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=32,\
    \ out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=512,\
    \ out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=32,\
    \ out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=512,\
    \ out_features=1, bias=True)\n  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors):\
    \ ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n     \
    \ (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1,\
    \ end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=32,\
    \ out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=512,\
    \ out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=32,\
    \ out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512,\
    \ out_features=512, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=512,\
    \ out_features=1, bias=True)\n  )\n)"
batch_norm_stats:
  desc: null
  value: '[]'
batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x00000237F7995F10>
